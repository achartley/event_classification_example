{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and exploration\n",
    "This notebook goes through data import and exploration using Numpy. You could also use Pandas to work with this data, but it's not very well suited to images. Regardless of which approach you choose, at some point you'll need to efficiently manipulate the images. Pandas is really good for tabular data, though,\n",
    "and we'll use Pandas here to get some descriptive statistics about our target values (energies and positions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, look at the data\n",
    "Sean Liddick provided information about how the file is formatted:\n",
    "\n",
    "The file contains one event per line, including the event energies and positions.\n",
    "The values are space-separated. The first 256 values correspond to the 16x16 detector image, flattened. \n",
    "The next values are, in order:\n",
    "Energy1, Xpos1, Ypos1, Energy2, Xpos2, Ypos2\n",
    "There are two types of events in the dataset. Single and double.\\\n",
    "For single events Xpos2 and Ypos2 are set to -100 instead of 0 to make a clear distinction.\\\n",
    "The energy units are MeV, and the position units are in pixels. Each pixel corresponds to one sensor,\n",
    "and is roughly equivalent to 3x3mm\n",
    "\n",
    "Open up the file and look at it. In most linux terminals you can also use the command\n",
    "`head` to display a set number of lines from the start of the file. We'll start with the first line.\n",
    "Usually you will also have some information about the file formatting.\n",
    "You can run shell commands inside the notebook by starting the line with an exclamation mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head -1 ../data/CeBr10k_1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last bit of information indicates that the event we printed above is a double event.\n",
    "We also note that the 256 \"pixel\" values in the detector image are integers, while the remaining\n",
    "6 values for energy and position are floats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import\n",
    "This is a bit of a \"hands-on\" approach that focuses on using base functions in python and\n",
    "Numpy to read the file and create some arrays we can work with.\n",
    "Reading the file is pretty straightforward, but some challenges appear when the file is large.\n",
    "We will prepare for that scenario from the get-go.\n",
    "\n",
    "CeBr10k_1.txt containes 10000 mixed single and double events.\\\n",
    "We set a datapath and filename. Note that we use the 'relative' path to our data, from the\n",
    "location of the notebook. This works well in a github repo where you control the folder structure.\n",
    "And if someone else will clone or fork the repo, they don't need to replace the paths.\n",
    "\n",
    "For small datafiles you can read the entire file into memory, store it as a list where each element is a line in the file, and work from there.\n",
    "```python\n",
    "with open(DATA_PATH + fname, \"r\") as datafile:\n",
    "    data = datafile.readlines()\n",
    "```\n",
    "You now have a list `data` containing all the lines in the file. Using the `with` statement is a shortcut so\n",
    "we don't need to manually close the file after opening it.\n",
    "However, reading the entire file into memory might not be possible, so we will read it line by line instead,\n",
    "looping over the file. This read only one line into memory at a time.\n",
    "\n",
    "Some resources for this exercise\n",
    "* [Python I/O File handling](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files)\n",
    "* [Numpy array indexing](https://numpy.org/doc/1.18/reference/arrays.indexing.html)\n",
    "* [Numpy's fromstring() function](https://numpy.org/doc/1.18/reference/generated/numpy.fromstring.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy module\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to data and filename. You can also store it a single variable\n",
    "# DATA_PATH = \"../data/CeBr10k_1.txt\" if you prefer. Here we expect to use at least the path itself later,\n",
    "# so we separate them.\n",
    "DATA_PATH = \"../data/\"\n",
    "fname = \"CeBr10k_1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store each image, energy, position, and labels. We know the filesize, so we could create\n",
    "# arrays that perfectly match the data, but let's assume we don't know how many lines we're going to\n",
    "# read. \n",
    "images = []\n",
    "energies = []\n",
    "positions = []\n",
    "labels = []\n",
    "# Open the file\n",
    "with open(DATA_PATH + fname, \"r\") as datafile:\n",
    "    # Loop over the file, line by line\n",
    "    for line in datafile:\n",
    "        \n",
    "        # The line is still a string when read from the file. We use numpys fromstring()\n",
    "        # to convert the line to a numpy array, specifying that each element is separated\n",
    "        # by a space. This does not convert the line in the file, only the \"copy\" that we have\n",
    "        # read into memory. fromstring() also removes any trailing newline ('\\n') characters\n",
    "        # so we don't have to worry about that. The values will be interpreted as floats.\n",
    "        line = np.fromstring(line, sep=' ')\n",
    "        \n",
    "        # Now we pick slices of the array. The first 256 elements are 'pixels' of the detector image\n",
    "        image = line[:256]\n",
    "        \n",
    "        # Get the two energies, at index 256 and 259.\n",
    "        energy = np.array((line[256], line[259]))\n",
    "        \n",
    "        # And the four position values\n",
    "        pos = np.array((line[257], line[258], line[260], line[261]))\n",
    "\n",
    "        # Set label for the event. If Energy2 is 0 it is a single event. Any other values corresponds \n",
    "        # to a double event. We label single events as type 0, and doubles as type 1. We could also \n",
    "        # use Xpos2 or Ypos2 for this purpose.\n",
    "        if energy[1] == 0:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "        # Finally, we take the separated arrays and add them to their respective \"storage\" lists.\n",
    "        images.append(image)\n",
    "        energies.append(energy)\n",
    "        positions.append(pos)\n",
    "        labels.append(label)\n",
    "\n",
    "        \n",
    "# We've now looped over the entire file. The only thing that remains is to convert the lists\n",
    "# to numpy arrays.\n",
    "images = np.array(images)\n",
    "energies = np.array(energies)\n",
    "positions = np.array(positions)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the shape of the arrays we've made as a quick check using\n",
    "# the shape property of numpy arrays.\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Energies shape:\",energies.shape)\n",
    "print(\"Positions shape:\", positions.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above tells us that we've got 10000 images, each of length 256, as well as two energy values for each image, and four positions. The images, energies, and positions arrays have two dimensions, while the labels array\n",
    "only has one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection of imported data\n",
    "If possible, it's usually a good idea to have a look at the data to confirm that\n",
    "the import gives a correct representation. In this case we want to check that the\n",
    "images look reasonable and match with positions and label.\n",
    "\n",
    "Resources:\n",
    "* [Matplotlib tutorial](https://matplotlib.org/tutorials/introductory/pyplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label of image 0:\", labels[0])\n",
    "print(\"Positions:\", positions[0])\n",
    "print(\"Energies:\", energies[0])\n",
    "print(\"\\nLabel of image 1:\", labels[1])\n",
    "print(\"Positions:\", positions[1])\n",
    "print(\"Energies:\", energies[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have two events. One double event and one single event.\n",
    "We can plot the detector images using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two pixel arrays side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "ax[0].plot(images[0])\n",
    "ax[0].set_title(\"Image 0, double\")\n",
    "ax[0].set_xlabel(\"Pixel number\")\n",
    "ax[0].set_ylabel(\"Pixel intensity\")\n",
    "\n",
    "ax[1].plot(images[1])\n",
    "ax[1].set_title(\"Image 1, single\")\n",
    "ax[1].set_xlabel(\"Pixel number\")\n",
    "ax[1].set_ylabel(\"Pixel intensity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above don't look like images, but we can still see a difference between them. \n",
    "Image 0 looks like it has two peaks, while image 1 looks like it only has one. \n",
    "Let's plot it like an actual image (or matrix), the way the detector is set up, instead.\n",
    "\n",
    "By default, the color of each pixel in the following plot is related to the pixel's value,\n",
    "but the value itself isn't displayed. So we're going to add a \"colorbar\" to each image that gives\n",
    "us that information. Additionaly, we will plot the position of the events as a red \"x\", to see if it matches.\n",
    "\n",
    "In our data, a single image is currently just a flat array of pixels. To plot it as an image, we must reshape it.\n",
    "This is a simple task when it's a numpy array, using a built-in function for arrays called \"reshape\". We will\n",
    "reshape the image to 16x16 pixels.\n",
    "\n",
    "Convention in this case is to plot the detector image with origins in the lower left, like a standard coordinate\n",
    "system. (This can be different from research group to research group). We specify this by passing the keyword \"origin\" to imshow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detector image, including positions and a colorbar.\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "image_0 = ax[0].imshow(images[0].reshape(16, 16), origin='lower')\n",
    "ax[0].plot(positions[0, 0], positions[0, 1], 'rx')\n",
    "ax[0].plot(positions[0, 2], positions[0, 3], 'rx')\n",
    "ax[0].set_title(\"image 0, type: \" + str(labels[0]))\n",
    "fig.colorbar(image_0, ax=ax[0])\n",
    "\n",
    "image_1 = ax[1].imshow(images[1].reshape(16, 16), origin='lower')\n",
    "ax[1].set_title(\"image 1, type: \" + str(labels[1]))\n",
    "ax[1].plot(positions[1, 0], positions[1, 1], 'rx')\n",
    "fig.colorbar(image_1, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is definitely not right with the positions here. It looks like the coordinates are flipped, especially\n",
    "when looking at the right image. This can be a result of the conversion from a flattened image to a 16x16 image,\n",
    "if it doesn't exactly reverse the way the image was originally written to file. One such case could be that the\n",
    "image was written to file in a column-major fashion. There are at least three ways we can correct this:\n",
    "* Reshape the arrays and specify the order (check numpy reshape documentation)\n",
    "* Transpose the reshaped arrays\n",
    "* Swap the x and y positions\n",
    "\n",
    "Transposing is very fast, so we'll go with that one this time.\n",
    "Let's plot the images again. With numpy you can get the transpose of an array as an attribute,\n",
    "\".T\". Recall also the positions and energies we printed above:\n",
    "```\n",
    "Label of image 0: 1\n",
    "Positions: [ 4.30804  6.70703 12.6208  13.0421 ]\n",
    "Energies: [0.942514 0.33576 ]\n",
    "\n",
    "Label of image 1: 0\n",
    "Positions: [  12.7629     1.52259 -100.      -100.     ]\n",
    "Energies: [0.302704 0.      ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rehape the whole set of images\n",
    "images = images.reshape((images.shape[0], 16, 16))\n",
    "\n",
    "# Transpose all the images\n",
    "images = np.transpose(images, (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot TRANSPOSED detector image, including positions and a colorbar\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "image_0 = ax[0].imshow(images[0], origin='lower')\n",
    "ax[0].plot(positions[0, 0], positions[0, 1], 'rx')\n",
    "ax[0].plot(positions[0, 2], positions[0, 3], 'rx')\n",
    "ax[0].set_title(\"image 0, type: \" + str(labels[0]))\n",
    "fig.colorbar(image_0, ax=ax[0])\n",
    "\n",
    "image_1 = ax[1].imshow(images[1], origin='lower')\n",
    "ax[1].set_title(\"image 1, type: \" + str(labels[1]))\n",
    "ax[1].plot(positions[1, 0], positions[1, 1], 'rx')\n",
    "fig.colorbar(image_1, ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much, much better. The positions fit, and the corresponding energies in the left image match the\n",
    "difference in pixel intensity. Most likely the simulation software is written with a slightly different\n",
    "convention than the way we read the file by default.\n",
    "\n",
    "You could also ask the question \"does it matter\"?\\\n",
    "Actually, for classification purposes it probably doesn't, because we want to know how many events there\n",
    "are in one image, rather than where they are. At least, we don't *want* the event position to matter when\n",
    "we're classifying, as that would indicate poor generalisation, or a bias in the distribution of events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking further\n",
    "It's not just the detector images themselves that are subject to some analysis before we start training.\n",
    "Our target values - energies, positions, labels - are also of interest. These can reveal other aspects of\n",
    "the data that we must take into account. Some questions that can be asked here are:\n",
    "* Is the dataset balanced?\n",
    "* What is the distribution of event energies?\n",
    "* What is the distribution of positions?\n",
    "* Are there differences between double and single events regarding these distributions?\n",
    "\n",
    "Then there's aggregated data, such as the separation distance between two detected particles in\n",
    "a double event. Are these evenly distributed?\n",
    "We'll try to answer these questions one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the dataset balanced?\n",
    "To determine this we can simply count the number of occurences for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Number of single events:\", counts[0])\n",
    "print(\"Number of double events:\", counts[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the file with 10k events we have 5002 single events and 4998 double events, so we should we very much good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of event energies?\n",
    "To look at single events and double events separately, we need to create two sets of indices.\n",
    "Given an array a, the condition a > 3 is a boolean array and since False is interpreted as 0, [np.nonzero](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html#numpy.nonzero)(a > 3) yields the indices of the a where the condition is true.\n",
    "\n",
    "Because all the arrays of data we've created are ordered identically, we can use these indices across\n",
    "all our arrays to keep single and double events separated if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make index arrays. np.nonzero returns a tuple where the first element is our index array.\n",
    "singles = np.nonzero(labels == 0)[0]\n",
    "doubles = np.nonzero(labels == 1)[0]\n",
    "\n",
    "# Check their length\n",
    "print(\"Singles:\", singles.shape, \" | Doubles:\", doubles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll plot histograms of the energies in single and double events. Keep in mind that the energy array\n",
    "is (E1, E2), so for single events we must specify that we're only interested in the column containing E1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.distplot(energies[singles, 0], bins=50, kde=False, ax=ax[0])\n",
    "ax[0].set_title(\"Energy distribution, single events\")\n",
    "ax[0].set_xlabel(\"Energy\")\n",
    "ax[0].set_ylabel(\"Observations\")\n",
    "\n",
    "sns.distplot(energies[doubles], bins=50, kde=False, ax=ax[1])\n",
    "ax[1].set_title(\"Energy distribution, double events\")\n",
    "ax[1].set_xlabel(\"Energy\")\n",
    "ax[1].set_ylabel(\"Observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairly uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of positions?\n",
    "On way to look at this is by using a scatterplot of positions. If the positions are also\n",
    "fairly uniform in their distribution, the scatterplot should resemple a square with size about equal\n",
    "to a detector image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "sns.scatterplot(positions[singles, 0], positions[singles, 1], alpha=0.2, ax=ax[0])\n",
    "ax[0].set_title(\"Positions of single events\")\n",
    "ax[0].set_xlabel(\"X [pixels]\")\n",
    "ax[0].set_ylabel(\"Y [pixels]\")\n",
    "\n",
    "sns.scatterplot(positions[doubles, 0], positions[doubles, 1], alpha=0.2, ax=ax[1])\n",
    "ax[1].set_title(\"Positions of double events, x1, y1\")\n",
    "ax[1].set_xlabel(\"X [pixels]\")\n",
    "ax[1].set_ylabel(\"Y [pixels]\")\n",
    "\n",
    "sns.scatterplot(positions[doubles, 2], positions[doubles, 3], alpha=0.2, ax=ax[2])\n",
    "ax[2].set_title(\"Positions of double events, x2, y2\")\n",
    "ax[2].set_xlabel(\"X [pixels]\")\n",
    "ax[2].set_ylabel(\"Y [pixels]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also fairly uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double-event specifics\n",
    "For double events there are a couple more things we can explore. Separation distances, as mentioned above,\n",
    "and also the relative energy. Let's calculate those and plot them, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separation distances\n",
    "We will simply use the euclidian distance between two points. A quick recap - if $p = (p_0,p_1)$\n",
    "and $q = (q_0,q_1)$ are the two points, then the distance $d(p,q)$ between them is given by\n",
    "$$d(\\mathbf{p},\\mathbf{q})=\\sqrt{(q_0-p_0)^2 + (q_1-p_1)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate separation distances for double events\n",
    "separation_distance = np.sqrt(\n",
    "    (positions[doubles, 2] - positions[doubles, 0])**2\n",
    "    + (positions[doubles, 3] - positions[doubles, 1])**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot distribution of separation distances\n",
    "fig, ax = plt.subplots()\n",
    "sns.distplot(separation_distance, kde=False, ax=ax)\n",
    "ax.set_title(\"Distribution of separation distances\")\n",
    "ax.set_xlabel(\"Separation distance [pixels]\")\n",
    "ax.set_ylabel(\"Occurences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative energy\n",
    "We can also look at how the relative energy is distributed. The quickest way to do this is the\n",
    "following\n",
    "\n",
    "$$E_{\\text{relative}} = \\frac{E_1}{E_2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative energies\n",
    "e_relative = energies[doubles, 0] / energies[doubles, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot distribution of relative energies\n",
    "fig, ax = plt.subplots()\n",
    "sns.distplot(e_relative, kde=False, ax=ax)\n",
    "ax.set_title(\"Distribution of relative energies\")\n",
    "ax.set_xlabel(\"Energy\")\n",
    "ax.set_ylabel(\"Occurences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that is not a very useful plot. Looks like we get some relative energies that are very large compared\n",
    "to the majority. Let's see how many are above 10, between 1 and 10, and below 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices for the intervals.\n",
    "above_ten = np.nonzero(e_relative > 10)[0]\n",
    "e_tmp = e_relative[np.nonzero(e_relative >= 1)]\n",
    "one_to_ten = np.nonzero(e_tmp <= 10)[0]\n",
    "less_than_one = np.nonzero(e_relative < 1)[0]\n",
    "print(\"Events with e_relative > 10:\", above_ten.shape[0])\n",
    "print(\"Events with 1 <= e_relative <= 10:\", one_to_ten.shape[0])\n",
    "print(\"Events with e_relative < 1:\", less_than_one.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 253 out of 5000 events that are above 10, and roughly half the events are between 1 and 10.\n",
    "So we're going to split these relative energies into three plots. [0, 1), [1, 10] and (10, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot distribution of relative energies for events with relative energy <= 10\n",
    "# We use the boolean array to get these events, e_relative[e_relative <= 10] reads as\n",
    "# \"The elements of e_relative on the indices where e_relative <= 10 is True\"\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "sns.distplot(e_relative[less_than_one], kde=False, ax=ax[0])\n",
    "ax[0].set_title(\"Distribution of relative energies < 1\")\n",
    "ax[0].set_xlabel(\"Relative energy\")\n",
    "ax[0].set_ylabel(\"Occurences\")\n",
    "sns.distplot(e_tmp[one_to_ten], kde=False, ax=ax[1])\n",
    "ax[1].set_title(\"Distribution of relative energies 1 <= e_rel <= 10\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Occurences\")\n",
    "ax[1].set_xlim([1, 10])\n",
    "sns.distplot(e_relative[above_ten], kde=False, ax=ax[2])\n",
    "ax[2].set_title(\"Relative energies > 10\")\n",
    "ax[2].set_xlabel(\"Relative energy\")\n",
    "ax[2].set_ylabel(\"Occurences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that most evens have a relative energy of up to 10, as a relative energy of less than 0.1 is\n",
    "effectively the same as a relative energy of above 10, since we always device E1/E2. The shape of the leftmost\n",
    "plot may be a bit unexpected, but technically the number of events between 0.5 to 1.0 should be somewhat close\n",
    "to the number of events between 1.0 and 2.0, if distributed evenly. We can check that by the eye, or use our\n",
    "existing indices to do some counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"0.5 to 1:\", np.nonzero(e_relative[less_than_one] >= 0.5)[0].shape[0])\n",
    "print(\"1.0 to 2:\", np.nonzero(e_relative[one_to_ten] < 2.0)[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate and save the data\n",
    "First, we separate the data into a *training set* and a *test set*. The test set will be used to give us an \"out-of-sample\"\n",
    "accuracy. To do this properly, the model will never see the test set in any way, shape, or form before we've trained, evaluated, and optimized it as far as we'd like to go. In other words, we use the training set to make the model as good as possible, and only then do we predict on the test set and report out-of-sample metrics.\n",
    "\n",
    "You can do the splitting of data manually by slicing the arrays, but scikit-learn has it's own function for doing this,\n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split).\n",
    "Instead of creating copies of the dataset, filling up often precious memory, we will work with indices that we\n",
    "pass around. This also makes it easier to trace any results back to the original inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices for all data\n",
    "x_idx = np.arange(images.shape[0])\n",
    "\n",
    "# Split the indices into training and test sets (take out 20% of the data as test)\n",
    "train_idx, test_idx, not_used1, not_used2 = train_test_split(x_idx, x_idx, test_size = 0.2)\n",
    "\n",
    "# Save the training and test data in the data folder\n",
    "# We also need to save the labels, energies, and positions. This allows us to\n",
    "# quickly load it if we need it.\n",
    "\n",
    "# Save the training data. np.save adds a \".npy\" file extension to the provided filename.\n",
    "# We save the files in the same folder as the original datafile.\n",
    "np.save(DATA_PATH + \"images_training\", images[train_idx])\n",
    "np.save(DATA_PATH + \"energies_training\", energies[train_idx])\n",
    "np.save(DATA_PATH + \"positions_training\", positions[train_idx])\n",
    "np.save(DATA_PATH + \"labels_training\", labels[train_idx])\n",
    "\n",
    "# Save the test data\n",
    "np.save(DATA_PATH + \"images_test\", images[test_idx])\n",
    "np.save(DATA_PATH + \"energies_test\", energies[test_idx])\n",
    "np.save(DATA_PATH + \"positions_test\", positions[test_idx])\n",
    "np.save(DATA_PATH + \"labels_test\", labels[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also opt to store the entire training and test sets as two files, by concatenating them.\n",
    "This is just personal preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hdf5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open separate files for saving training and test datasets\n",
    "data_training = h5py.File(DATA_PATH + \"data_training.hdf5\", \"w\")\n",
    "data_test = h5py.File(DATA_PATH + \"data_test.hdf5\", \"w\")\n",
    "\n",
    "# Training data\n",
    "data_training.create_dataset('images', data=images[train_idx])\n",
    "data_training.create_dataset('energies', data=energies[train_idx])\n",
    "data_training.create_dataset('positions', data=positions[train_idx])\n",
    "data_training.create_dataset('labels', data=labels[train_idx])\n",
    "data_training.close()\n",
    "\n",
    "# Test data\n",
    "data_test.create_dataset('images', data=images[test_idx])\n",
    "data_test.create_dataset('energies', data=energies[test_idx])\n",
    "data_test.create_dataset('positions', data=positions[test_idx])\n",
    "data_test.create_dataset('labels', data=labels[test_idx])\n",
    "data_test.close()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
